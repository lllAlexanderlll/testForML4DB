# Neural Network
layer:
  - 512
  - 256
loss_function: q_loss
dropout: 0.2
learning_rate: 0.0001
kernel_initializer: normal
activation_strategy: relu
len_input: