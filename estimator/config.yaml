# Neural Network
layer:
  - 512
  - 256
loss_function: mean_squared_error
dropout: 0.2
learning_rate: 0.0001
kernel_initializer: normal
activation_strategy: relu
len_input: